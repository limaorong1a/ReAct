# 服务器训练指南 - 无 GPU 本地环境

## 方案一：AutoDL（推荐）

### 1. 注册和租用

1. **注册账号**
   - 访问：https://www.autodl.com/
   - 注册并充值（建议充值 50-100 元）

2. **租用实例**
   - 进入「算力市场」
   - 推荐配置：
     - GPU：RTX 4090 (24GB) 或 RTX 3090 (24GB)
     - 镜像：PyTorch 2.1.0 / Python 3.10 / CUDA 12.1
     - 磁盘：100GB（存放模型和数据）
   - 价格：约 2-3 元/小时

3. **启动实例**
   - 点击「创建实例」
   - 记录 SSH 连接信息

### 2. 上传项目文件

**方法 A：使用 JupyterLab 上传（简单）**
```bash
# 在 AutoDL 控制台点击「JupyterLab」按钮
# 在 JupyterLab 界面上传文件
```

**方法 B：使用 SSH + SCP（推荐）**
```bash
# 在本地 PowerShell 中执行
# 将整个项目打包
cd D:\project
tar -czf ReAct.tar.gz ReAct

# 上传到服务器（替换为你的连接信息）
scp -P <端口> ReAct.tar.gz root@<服务器IP>:~

# SSH 连接到服务器
ssh -p <端口> root@<服务器IP>

# 解压
tar -xzf ReAct.tar.gz
cd ReAct
```

**方法 C：使用 Git（最佳实践）**
```bash
# 在本地先提交代码
cd D:\project\ReAct
git add .
git commit -m "准备服务器训练"
git push

# 在服务器上克隆
ssh -p <端口> root@<服务器IP>
git clone <你的仓库地址>
cd ReAct
```

### 3. 安装依赖

```bash
# 安装 LLaMA-Factory
pip install llamafactory -U

# 或从源码安装（推荐）
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e .[torch,metrics]

# 返回项目目录
cd ~/ReAct
```

### 4. 配置数据集

在 LLaMA-Factory 的 `data/dataset_info.json` 中添加你的数据集：

```bash
# 编辑配置文件
nano ~/LLaMA-Factory/data/dataset_info.json
```

添加以下内容：
```json
{
  "react_training": {
    "file_name": "/root/ReAct/react_train_alpaca.json",
    "formatting": "alpaca"
  }
}
```

或者如果使用 ShareGPT 格式：
```json
{
  "react_training": {
    "file_name": "/root/ReAct/react_train_sharegpt.json",
    "formatting": "sharegpt",
    "columns": {
      "messages": "conversations"
    }
  }
}
```

### 5. 修改训练配置

编辑 `llama_factory_train_config.yaml`：

```yaml
# 如果模型需要下载，确保路径正确
model_name_or_path: Qwen/Qwen2.5-7B-Instruct

# 或者预先下载到本地
# model_name_or_path: /root/models/Qwen2.5-7B-Instruct
```

### 6. 开始训练

```bash
# 进入 LLaMA-Factory 目录
cd ~/LLaMA-Factory

# 使用配置文件启动训练
llamafactory-cli train ~/ReAct/llama_factory_train_config.yaml

# 或者使用 nohup 后台运行（推荐）
nohup llamafactory-cli train ~/ReAct/llama_factory_train_config.yaml > train.log 2>&1 &

# 查看日志
tail -f train.log
```

### 7. 监控训练

**查看 TensorBoard**：
```bash
# 在服务器上启动 TensorBoard
tensorboard --logdir=./logs --port=6006

# AutoDL 会提供一个访问链接，在浏览器中打开
```

**查看 GPU 使用情况**：
```bash
# 实时监控
watch -n 1 nvidia-smi
```

### 8. 下载训练好的模型

**方法 A：使用 SCP**
```bash
# 在本地 PowerShell 中执行
scp -P <端口> -r root@<服务器IP>:~/ReAct/output/qwen2.5-7b-react ./
```

**方法 B：使用 JupyterLab**
- 在 JupyterLab 中压缩文件
- 直接下载压缩包

**方法 C：上传到云存储**
```bash
# 可以上传到 HuggingFace
huggingface-cli login
huggingface-cli upload <你的用户名>/qwen2.5-7b-react ./output/qwen2.5-7b-react
```

### 9. 关闭实例（重要！）

训练完成后：
1. 确保模型已下载到本地
2. 在 AutoDL 控制台点击「关机」
3. 避免继续扣费

---

## 方案二：阿里云 / 腾讯云 GPU 服务器

### 优势
- 更稳定，适合长期使用
- 可以配置更强的机器
- 企业级支持

### 缺点
- 价格较高（约 10-20 元/小时）
- 需要自己配置环境

### 推荐配置
- **阿里云 PAI-DSW**：预装深度学习环境
- **腾讯云 Ti-ONE**：类似服务

### 操作步骤
与 AutoDL 类似，主要区别是环境需要从头配置。

---

## 方案三：Google Colab（免费但受限）

### 优势
- 免费提供 GPU（Tesla T4）
- 无需配置

### 缺点
- 免费版有时间限制（12 小时）
- 可能被断线
- 显存较小（15GB）

### 操作步骤

1. **上传到 Google Drive**
```python
# 在 Colab 中
from google.colab import drive
drive.mount('/content/drive')

# 上传项目到 Drive
%cd /content/drive/MyDrive
!git clone <你的仓库>
%cd ReAct
```

2. **安装并训练**
```python
# 安装依赖
!pip install llamafactory

# 配置数据集（同上）

# 训练（需要在 12 小时内完成）
!llamafactory-cli train llama_factory_train_config.yaml
```

### Colab Pro（推荐）
- 9.99 美元/月
- 提供更好的 GPU（A100 可选）
- 无时间限制

---

## 方案四：Kaggle（免费 GPU）

### 优势
- 免费提供 P100 / T4 GPU
- 每周 30 小时 GPU 时间

### 缺点
- 网络环境限制（需要开启互联网访问）

### 操作步骤
1. 创建 Kaggle Notebook
2. 启用 GPU（Settings → Accelerator → GPU）
3. 上传数据和代码
4. 运行训练

---

## 💡 最佳实践建议

### 1. 预算考虑
- **<100元**：使用 Google Colab Pro 或 Kaggle
- **100-200元**：AutoDL 租用几天
- **长期使用**：月付云服务器

### 2. 训练策略
```yaml
# 如果显存不足，修改配置：
per_device_train_batch_size: 1  # 降低批次
gradient_accumulation_steps: 16  # 增加累积步数
lora_rank: 8  # 降低 LoRA 秩
cutoff_len: 1024  # 减小序列长度
```

### 3. 断点续训
```yaml
# 在配置文件中添加
resume_from_checkpoint: true
```

如果训练中断，可以从最后一个检查点继续。

### 4. 数据传输优化
- 使用 Git 管理代码（不要传大文件）
- 模型文件直接在服务器下载
- 训练数据可以提前上传

---

## 🔧 常见问题

### Q1: 模型下载很慢怎么办？
```bash
# 使用镜像源
export HF_ENDPOINT=https://hf-mirror.com
pip install -U huggingface_hub

# 或使用 ModelScope（国内）
pip install modelscope
```

### Q2: 训练中断怎么办？
- 使用 `nohup` 或 `screen` 保持后台运行
- 设置较小的 `save_steps` 频繁保存
- 启用 `resume_from_checkpoint`

### Q3: 显存不足怎么办？
参考上面的"训练策略"部分，降低显存占用。

### Q4: 如何估算训练时间？
- 100 条样本，3 epochs：约 30 分钟 - 1 小时
- 1000 条样本，3 epochs：约 3-6 小时
- 具体取决于序列长度和 GPU 性能

---

## 📞 推荐方案总结

**新手推荐**：AutoDL
- 操作简单
- 价格便宜
- 随用随关

**临时测试**：Google Colab 免费版

**正式训练**：AutoDL 或阿里云 PAI-DSW

如有问题随时询问！





