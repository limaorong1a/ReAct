"""
å°†ç”Ÿæˆçš„ ReAct ç¤ºä¾‹è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
æ”¯æŒ LLaMA-Factory å’Œ Unsloth æ ¼å¼
"""

import json
import os
from pathlib import Path
from typing import List, Dict

def load_all_samples(base_dir: str = ".") -> List[Dict]:
    """åŠ è½½æ‰€æœ‰ä»»åŠ¡ç±»å‹çš„ç¤ºä¾‹"""
    
    task_types = [
        "generated_samples_put",
        "generated_samples_clean", 
        "generated_samples_cool",
        "generated_samples_heat",
        "generated_samples_puttwo",
        "generated_samples_examine"
    ]
    
    all_samples = []
    
    for task_type in task_types:
        task_dir = Path(base_dir) / task_type
        if not task_dir.exists():
            print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {task_dir}")
            continue
            
        # è¯»å–æ‰€æœ‰ sample_*.json æ–‡ä»¶
        sample_files = sorted(task_dir.glob("sample_*.json"))
        
        for sample_file in sample_files:
            try:
                with open(sample_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    all_samples.append({
                        "task_type": task_type,
                        "file": str(sample_file),
                        "data": data
                    })
            except Exception as e:
                print(f"âŒ è¯»å–å¤±è´¥ {sample_file}: {e}")
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(all_samples)} ä¸ªç¤ºä¾‹")
    return all_samples


def convert_to_llama_factory_format(samples: List[Dict]) -> List[Dict]:
    """è½¬æ¢ä¸º LLaMA-Factory æ ¼å¼ï¼ˆAlpaca/ShareGPTï¼‰"""
    
    training_data = []
    
    for idx, sample in enumerate(samples):
        # æå–ç¤ºä¾‹å†…å®¹
        data = sample["data"]
        
        # é€šå¸¸ JSON æ ¼å¼æ˜¯: {"task_name": "å®Œæ•´ç¤ºä¾‹æ–‡æœ¬"}
        for key, value in data.items():
            if key.startswith("generated_") or key.startswith("react_"):
                example_text = value
                
                # åˆ†ç¦»ä»»åŠ¡æè¿°å’Œæ‰§è¡Œè¿‡ç¨‹
                lines = example_text.strip().split('\n')
                
                # æå–ç¯å¢ƒæè¿°å’Œä»»åŠ¡
                environment = lines[0] if lines else ""
                task = lines[1] if len(lines) > 1 else ""
                
                # æå– ReAct æ‰§è¡Œè¿‡ç¨‹ï¼ˆä»ç¬¬ä¸‰è¡Œå¼€å§‹ï¼‰
                react_process = '\n'.join(lines[2:]) if len(lines) > 2 else ""
                
                # æ„å»ºè®­ç»ƒæ ·æœ¬
                training_sample = {
                    "instruction": f"{environment}\n{task}\n\nPlease solve this task using ReAct (Reasoning + Acting) approach. Think step by step, take actions, and observe the results.",
                    "input": "",
                    "output": react_process
                }
                
                training_data.append(training_sample)
                break
    
    return training_data


def convert_to_sharegpt_format(samples: List[Dict]) -> List[Dict]:
    """è½¬æ¢ä¸º ShareGPT æ ¼å¼ï¼ˆæ¨èç”¨äºå¯¹è¯æ¨¡å‹ï¼‰"""
    
    training_data = []
    
    for sample in samples:
        data = sample["data"]
        
        for key, value in data.items():
            if key.startswith("generated_") or key.startswith("react_"):
                example_text = value
                lines = example_text.strip().split('\n')
                
                environment = lines[0] if lines else ""
                task = lines[1] if len(lines) > 1 else ""
                react_process = '\n'.join(lines[2:]) if len(lines) > 2 else ""
                
                # ShareGPT æ ¼å¼
                conversation = {
                    "conversations": [
                        {
                            "from": "human",
                            "value": f"{environment}\n{task}\n\nPlease solve this task using ReAct (Reasoning + Acting) approach."
                        },
                        {
                            "from": "gpt",
                            "value": react_process
                        }
                    ]
                }
                
                training_data.append(conversation)
                break
    
    return training_data


def split_train_test(data: List[Dict], test_ratio: float = 0.1):
    """åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
    
    import random
    random.shuffle(data)
    
    split_idx = int(len(data) * (1 - test_ratio))
    train_data = data[:split_idx]
    test_data = data[split_idx:]
    
    return train_data, test_data


def main():
    print("ğŸš€ å¼€å§‹å‡†å¤‡è®­ç»ƒæ•°æ®...")
    
    # 1. åŠ è½½æ‰€æœ‰ç¤ºä¾‹
    samples = load_all_samples()
    
    if not samples:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç¤ºä¾‹æ•°æ®ï¼")
        return
    
    # 2. è½¬æ¢ä¸º Alpaca æ ¼å¼ï¼ˆé€‚åˆæŒ‡ä»¤å¾®è°ƒï¼‰
    print("\nğŸ“ è½¬æ¢ä¸º Alpaca æ ¼å¼...")
    alpaca_data = convert_to_llama_factory_format(samples)
    train_alpaca, test_alpaca = split_train_test(alpaca_data)
    
    with open("react_train_alpaca.json", 'w', encoding='utf-8') as f:
        json.dump(train_alpaca, f, ensure_ascii=False, indent=2)
    
    with open("react_test_alpaca.json", 'w', encoding='utf-8') as f:
        json.dump(test_alpaca, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Alpaca æ ¼å¼: è®­ç»ƒé›† {len(train_alpaca)} æ¡, æµ‹è¯•é›† {len(test_alpaca)} æ¡")
    
    # 3. è½¬æ¢ä¸º ShareGPT æ ¼å¼ï¼ˆé€‚åˆå¯¹è¯æ¨¡å‹ï¼‰
    print("\nğŸ’¬ è½¬æ¢ä¸º ShareGPT æ ¼å¼...")
    sharegpt_data = convert_to_sharegpt_format(samples)
    train_sharegpt, test_sharegpt = split_train_test(sharegpt_data)
    
    with open("react_train_sharegpt.json", 'w', encoding='utf-8') as f:
        json.dump(train_sharegpt, f, ensure_ascii=False, indent=2)
    
    with open("react_test_sharegpt.json", 'w', encoding='utf-8') as f:
        json.dump(test_sharegpt, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ShareGPT æ ¼å¼: è®­ç»ƒé›† {len(train_sharegpt)} æ¡, æµ‹è¯•é›† {len(test_sharegpt)} æ¡")
    
    # 4. ç”Ÿæˆæ•°æ®ç»Ÿè®¡
    print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  - æ€»æ ·æœ¬æ•°: {len(samples)}")
    print(f"  - è®­ç»ƒæ ·æœ¬: {len(train_alpaca)}")
    print(f"  - æµ‹è¯•æ ·æœ¬: {len(test_alpaca)}")
    
    # ç»Ÿè®¡ä»»åŠ¡ç±»å‹åˆ†å¸ƒ
    task_counts = {}
    for sample in samples:
        task_type = sample["task_type"]
        task_counts[task_type] = task_counts.get(task_type, 0) + 1
    
    print("\nğŸ“‹ ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
    for task_type, count in sorted(task_counts.items()):
        print(f"  - {task_type}: {count} ä¸ª")
    
    print("\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. ä½¿ç”¨ LLaMA-Factory è®­ç»ƒ: å°† JSON æ–‡ä»¶æ”¾åˆ° LLaMA-Factory/data/ ç›®å½•")
    print("2. æˆ–ä½¿ç”¨ Unsloth/Axolotl è®­ç»ƒ")


if __name__ == "__main__":
    main()

