#!/bin/bash
# RTX 5090 æœåŠ¡å™¨è‡ªåŠ¨è®­ç»ƒè„šæœ¬
# è¿è¡Œæ–¹å¼: bash server_auto_train.sh

set -e

# ====================================
# é…ç½®åŒºåŸŸ
# ====================================

PROJECT_DIR="/data_nvme/react_training"
MODEL_NAME="Qwen/Qwen2.5-7B-Instruct"
OUTPUT_NAME="qwen2.5-7b-react"

# è®­ç»ƒå‚æ•°ï¼ˆé’ˆå¯¹ RTX 5090 ä¼˜åŒ–ï¼‰
BATCH_SIZE=4
GRAD_ACCUM=4
LORA_RANK=32
EPOCHS=3
LEARNING_RATE=5e-5

# ====================================

echo "ğŸš€ ReAct æ¨¡å‹è‡ªåŠ¨è®­ç»ƒè„šæœ¬"
echo "================================"
echo "GPU: RTX 5090 D"
echo "æ¨¡å‹: ${MODEL_NAME}"
echo "è¾“å‡º: ${OUTPUT_NAME}"
echo "================================"
echo ""

# Step 1: ç¯å¢ƒæ£€æŸ¥
echo "ğŸ” Step 1: ç¯å¢ƒæ£€æŸ¥"
echo "-------------------"

# æ£€æŸ¥ CUDA
if ! command -v nvidia-smi &> /dev/null; then
    echo "âŒ æœªæ£€æµ‹åˆ° NVIDIA GPU"
    exit 1
fi

echo "GPU ä¿¡æ¯:"
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader

# æ£€æŸ¥ Python
if ! command -v python &> /dev/null; then
    echo "âŒ æœªæ‰¾åˆ° Python"
    exit 1
fi

echo "Python ç‰ˆæœ¬: $(python --version)"

# æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
if [ ! -d "${PROJECT_DIR}/react_env" ]; then
    echo "âš ï¸  è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º..."
    cd ${PROJECT_DIR}
    python -m venv react_env
fi

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo "âœ… æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ"
source ${PROJECT_DIR}/react_env/bin/activate

# Step 2: å®‰è£…ä¾èµ–
echo ""
echo "ğŸ“¦ Step 2: æ£€æŸ¥ä¾èµ–"
echo "-------------------"

if ! python -c "import llamafactory" 2>/dev/null; then
    echo "âš ï¸  LLaMA-Factory æœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…..."
    
    cd ${PROJECT_DIR}
    
    # å®‰è£… PyTorchï¼ˆå¦‚æœéœ€è¦ï¼‰
    if ! python -c "import torch" 2>/dev/null; then
        echo "å®‰è£… PyTorch..."
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    fi
    
    # å…‹éš†å¹¶å®‰è£… LLaMA-Factory
    if [ ! -d "LLaMA-Factory" ]; then
        git clone https://github.com/hiyouga/LLaMA-Factory.git
    fi
    
    cd LLaMA-Factory
    pip install -e .[torch,metrics]
    
    # å®‰è£…åŠ é€Ÿåº“ï¼ˆå¯é€‰ï¼‰
    echo "å®‰è£…åŠ é€Ÿåº“..."
    pip install flash-attn --no-build-isolation || echo "âš ï¸  Flash Attention å®‰è£…å¤±è´¥ï¼ˆå¯é€‰ï¼‰"
    
    cd ${PROJECT_DIR}
else
    echo "âœ… LLaMA-Factory å·²å®‰è£…"
fi

# éªŒè¯ PyTorch
echo ""
echo "éªŒè¯ PyTorch å’Œ CUDA:"
python << 'PYTHON_CHECK'
import torch
print(f"  PyTorch: {torch.__version__}")
print(f"  CUDA å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"  GPU: {torch.cuda.get_device_name(0)}")
    print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
PYTHON_CHECK

# Step 3: æ£€æŸ¥æ•°æ®
echo ""
echo "ğŸ“Š Step 3: æ£€æŸ¥è®­ç»ƒæ•°æ®"
echo "-------------------"

if [ ! -f "${PROJECT_DIR}/data/react_train_alpaca.json" ]; then
    echo "âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®"
    echo "è¯·å…ˆè¿è¡Œ: python prepare_training_data.py"
    echo "æˆ–ä½¿ç”¨ä¸Šä¼ è„šæœ¬ä¸Šä¼ æ•°æ®"
    exit 1
fi

echo "âœ… è®­ç»ƒæ•°æ®: $(wc -l < ${PROJECT_DIR}/data/react_train_alpaca.json) è¡Œ"
echo "âœ… æµ‹è¯•æ•°æ®: $(wc -l < ${PROJECT_DIR}/data/react_test_alpaca.json) è¡Œ"

# Step 4: é…ç½® dataset_info.json
echo ""
echo "âš™ï¸  Step 4: é…ç½®æ•°æ®é›†"
echo "-------------------"

cat > ${PROJECT_DIR}/LLaMA-Factory/data/dataset_info.json << EOF
{
  "react_training": {
    "file_name": "${PROJECT_DIR}/data/react_train_alpaca.json",
    "columns": {
      "prompt": "instruction",
      "query": "input",
      "response": "output"
    }
  },
  "react_testing": {
    "file_name": "${PROJECT_DIR}/data/react_test_alpaca.json",
    "columns": {
      "prompt": "instruction",
      "query": "input",
      "response": "output"
    }
  }
}
EOF

echo "âœ… dataset_info.json é…ç½®å®Œæˆ"

# Step 5: å¼€å§‹è®­ç»ƒ
echo ""
echo "ğŸ¯ Step 5: å¼€å§‹è®­ç»ƒ"
echo "-------------------"
echo ""
echo "è®­ç»ƒé…ç½®:"
echo "  - Batch Size: ${BATCH_SIZE}"
echo "  - Gradient Accumulation: ${GRAD_ACCUM}"
echo "  - Effective Batch: $((BATCH_SIZE * GRAD_ACCUM))"
echo "  - LoRA Rank: ${LORA_RANK}"
echo "  - Epochs: ${EPOCHS}"
echo "  - Learning Rate: ${LEARNING_RATE}"
echo ""

read -p "ç¡®è®¤å¼€å§‹è®­ç»ƒï¼Ÿ(y/n): " confirm
if [ "$confirm" != "y" ]; then
    echo "âŒ è®­ç»ƒå·²å–æ¶ˆ"
    exit 0
fi

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p ${PROJECT_DIR}/logs

# è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
echo "è®­ç»ƒå¼€å§‹æ—¶é—´: $(date)" > ${PROJECT_DIR}/logs/train_start.log

cd ${PROJECT_DIR}/LLaMA-Factory

# å¯åŠ¨è®­ç»ƒï¼ˆä½¿ç”¨ nohup åå°è¿è¡Œï¼‰
nohup llamafactory-cli train \
    --stage sft \
    --do_train \
    --model_name_or_path ${MODEL_NAME} \
    --dataset react_training \
    --template qwen \
    --finetuning_type lora \
    --lora_target all \
    --lora_rank ${LORA_RANK} \
    --lora_alpha $((LORA_RANK * 2)) \
    --lora_dropout 0.05 \
    --use_rslora true \
    --output_dir ${PROJECT_DIR}/output/${OUTPUT_NAME} \
    --overwrite_cache \
    --overwrite_output_dir \
    --cutoff_len 2048 \
    --preprocessing_num_workers 8 \
    --per_device_train_batch_size ${BATCH_SIZE} \
    --per_device_eval_batch_size ${BATCH_SIZE} \
    --gradient_accumulation_steps ${GRAD_ACCUM} \
    --lr_scheduler_type cosine \
    --logging_steps 10 \
    --warmup_ratio 0.1 \
    --save_steps 100 \
    --eval_steps 100 \
    --evaluation_strategy steps \
    --load_best_model_at_end \
    --learning_rate ${LEARNING_RATE} \
    --num_train_epochs ${EPOCHS} \
    --val_size 0.1 \
    --plot_loss \
    --bf16 \
    --gradient_checkpointing \
    --optim adamw_torch_fused \
    --logging_dir ${PROJECT_DIR}/logs \
    --report_to tensorboard \
    > ${PROJECT_DIR}/logs/train.log 2>&1 &

# è®°å½•è¿›ç¨‹ ID
TRAIN_PID=$!
echo ${TRAIN_PID} > ${PROJECT_DIR}/train.pid

echo ""
echo "================================"
echo "âœ¨ è®­ç»ƒå·²åœ¨åå°å¯åŠ¨ï¼"
echo "================================"
echo ""
echo "è¿›ç¨‹ ID: ${TRAIN_PID}"
echo "æ—¥å¿—æ–‡ä»¶: ${PROJECT_DIR}/logs/train.log"
echo ""
echo "ç›‘æ§å‘½ä»¤:"
echo "  - æŸ¥çœ‹æ—¥å¿—: tail -f ${PROJECT_DIR}/logs/train.log"
echo "  - ç›‘æ§ GPU: watch -n 1 nvidia-smi"
echo "  - TensorBoard: tensorboard --logdir=${PROJECT_DIR}/logs --host=0.0.0.0 --port=6006"
echo ""
echo "ç®¡ç†å‘½ä»¤:"
echo "  - æŸ¥çœ‹è¿›ç¨‹: ps -p ${TRAIN_PID}"
echo "  - åœæ­¢è®­ç»ƒ: kill ${TRAIN_PID}"
echo ""

# å¯åŠ¨ GPU ç›‘æ§ï¼ˆå¯é€‰ï¼‰
read -p "æ˜¯å¦å¯åŠ¨ GPU ç›‘æ§ï¼Ÿ(y/n): " monitor
if [ "$monitor" = "y" ]; then
    nohup bash -c 'while true; do nvidia-smi --query-gpu=timestamp,name,utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv >> '${PROJECT_DIR}'/logs/gpu_monitor.csv; sleep 60; done' > /dev/null 2>&1 &
    GPU_MONITOR_PID=$!
    echo ${GPU_MONITOR_PID} > ${PROJECT_DIR}/gpu_monitor.pid
    echo "âœ… GPU ç›‘æ§å·²å¯åŠ¨ (PID: ${GPU_MONITOR_PID})"
    echo "   æ—¥å¿—: ${PROJECT_DIR}/logs/gpu_monitor.csv"
fi

# ç­‰å¾…å‡ ç§’å¹¶æ˜¾ç¤ºåˆå§‹æ—¥å¿—
echo ""
echo "åˆå§‹æ—¥å¿—è¾“å‡º:"
echo "-------------------"
sleep 5
tail -n 20 ${PROJECT_DIR}/logs/train.log

echo ""
echo "ğŸ’¡ æç¤º: è®­ç»ƒé¢„è®¡éœ€è¦ 3-6 å°æ—¶"
echo "ğŸ’¡ å»ºè®®: ä½¿ç”¨ tmux æˆ–å®šæœŸæ£€æŸ¥æ—¥å¿—"

